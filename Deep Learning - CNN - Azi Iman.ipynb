{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builing CNN for Image Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential     # making ANN and initialize\n",
    "from keras.layers import Convolution2D  # ADDING CONCOLUTIONl layers\n",
    "from keras.layers import MaxPooling2D   # adding pooling step  2d its for pcis and 3D is for movies \n",
    "from keras.layers import Flatten        # flt poolling into large vector\n",
    "from keras.layers import Dense          # adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "Classifier.add(Convolution2D(64,3,3,input_shape=(64,64,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# add another layer , this time i dont need input dims\n",
    "\n",
    "Classifier.add(Convolution2D(64,3,3, activation='relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Classifier.add(Convolution2D(64,3,3, activation='relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Classifier.add(Convolution2D(64,3,3, activation='relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "Classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Dense(128, activation ='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Dense(128, activation ='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Dense(128, activation ='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "Classifier.add(Dense(output_dim =1 , activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 117 images belonging to 2 classes.\n",
      "Found 19 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "135/135 [==============================] - 98s 727ms/step - loss: 7.8892e-04 - acc: 1.0000 - val_loss: 1.2440 - val_acc: 0.8356\n",
      "Epoch 2/25\n",
      "135/135 [==============================] - 97s 717ms/step - loss: 0.0191 - acc: 0.9926 - val_loss: 1.0006 - val_acc: 0.8611\n",
      "Epoch 3/25\n",
      "135/135 [==============================] - 96s 712ms/step - loss: 0.0490 - acc: 0.9911 - val_loss: 1.8485 - val_acc: 0.8333\n",
      "Epoch 4/25\n",
      "135/135 [==============================] - 95s 705ms/step - loss: 0.0601 - acc: 0.9800 - val_loss: 1.7884 - val_acc: 0.8194\n",
      "Epoch 5/25\n",
      "135/135 [==============================] - 91s 677ms/step - loss: 0.0200 - acc: 0.9926 - val_loss: 1.2896 - val_acc: 0.9028\n",
      "Epoch 6/25\n",
      "135/135 [==============================] - 88s 655ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.6552 - val_acc: 0.8904\n",
      "Epoch 7/25\n",
      "135/135 [==============================] - 89s 660ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.7715 - val_acc: 0.8889\n",
      "Epoch 8/25\n",
      "135/135 [==============================] - 89s 663ms/step - loss: 0.0103 - acc: 0.9985 - val_loss: 1.3291 - val_acc: 0.9167\n",
      "Epoch 9/25\n",
      "135/135 [==============================] - 95s 702ms/step - loss: 0.0365 - acc: 0.9896 - val_loss: 1.4352 - val_acc: 0.8889\n",
      "Epoch 10/25\n",
      "135/135 [==============================] - 92s 679ms/step - loss: 0.0350 - acc: 0.9889 - val_loss: 1.2219 - val_acc: 0.8889\n",
      "Epoch 11/25\n",
      "135/135 [==============================] - 90s 664ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 1.5051 - val_acc: 0.8356\n",
      "Epoch 12/25\n",
      "135/135 [==============================] - 90s 670ms/step - loss: 0.0537 - acc: 0.9867 - val_loss: 1.2272 - val_acc: 0.8889\n",
      "Epoch 13/25\n",
      "135/135 [==============================] - 92s 681ms/step - loss: 0.0499 - acc: 0.9845 - val_loss: 1.1729 - val_acc: 0.8472\n",
      "Epoch 14/25\n",
      "135/135 [==============================] - 91s 671ms/step - loss: 0.0147 - acc: 0.9941 - val_loss: 1.2710 - val_acc: 0.9167\n",
      "Epoch 15/25\n",
      "135/135 [==============================] - 95s 702ms/step - loss: 0.0122 - acc: 0.9970 - val_loss: 1.5414 - val_acc: 0.8889\n",
      "Epoch 16/25\n",
      "135/135 [==============================] - 93s 688ms/step - loss: 0.0511 - acc: 0.9852 - val_loss: 1.2564 - val_acc: 0.8356\n",
      "Epoch 17/25\n",
      "135/135 [==============================] - 95s 703ms/step - loss: 0.0047 - acc: 0.9970 - val_loss: 1.4733 - val_acc: 0.8611\n",
      "Epoch 18/25\n",
      "135/135 [==============================] - 90s 665ms/step - loss: 3.6896e-04 - acc: 1.0000 - val_loss: 1.6481 - val_acc: 0.8889\n",
      "Epoch 19/25\n",
      "135/135 [==============================] - 94s 697ms/step - loss: 4.3890e-04 - acc: 1.0000 - val_loss: 1.6605 - val_acc: 0.8611\n",
      "Epoch 20/25\n",
      "135/135 [==============================] - 90s 669ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.3520 - val_acc: 0.8333\n",
      "Epoch 21/25\n",
      "135/135 [==============================] - 94s 694ms/step - loss: 1.0071e-04 - acc: 1.0000 - val_loss: 1.9945 - val_acc: 0.8493\n",
      "Epoch 22/25\n",
      "135/135 [==============================] - 95s 702ms/step - loss: 7.8815e-05 - acc: 1.0000 - val_loss: 2.0285 - val_acc: 0.8472\n",
      "Epoch 23/25\n",
      "135/135 [==============================] - 95s 703ms/step - loss: 5.2479e-05 - acc: 1.0000 - val_loss: 2.2822 - val_acc: 0.8194\n",
      "Epoch 24/25\n",
      "135/135 [==============================] - 92s 678ms/step - loss: 1.2338e-05 - acc: 1.0000 - val_loss: 2.0816 - val_acc: 0.8472\n",
      "Epoch 25/25\n",
      "135/135 [==============================] - 97s 716ms/step - loss: 0.0937 - acc: 0.9689 - val_loss: 1.0071 - val_acc: 0.6944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12eeb6710>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "import tensorflow as TF \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# we dont change anything on the below , just copy and paste from keras doc\n",
    "# we create object train_datagen to use for other part\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# another datagen object for test to apply on test set\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# we change name and directory\n",
    "# also target size should the same 1st step on convo;ution2d\n",
    "\n",
    "# batch size is 32 \n",
    "\n",
    "# class mode is okay as we only have 2 category 0/1 for output\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'Data/Train',\n",
    "        target_size=(64,64), # target size is the dim on CNN model on convultion2d which 64,64\n",
    "        batch_size=5,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "\n",
    "# now test data\n",
    "# we change the direcotry and traget size\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'Data/Test',\n",
    "        target_size=(64, 64), # becasue input for convultion is 64\n",
    "        batch_size=4,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "# now fitting model \n",
    "\n",
    "# sample is 8000 as we have 4000 for dog and 4000 for cat\n",
    "\n",
    "# number of epoch for training 50 is high we can choose 25 for iteration\n",
    "\n",
    "Classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=135,\n",
    "        epochs=25,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=19)  # number of images in test _set which is 2000 1k for cat and 1 k for dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.save_weights('AziCNN.hdf5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.load_weights('AziCNN.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Azadeh': 0, 'Iman': 1}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to test the model  \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "test_image=image.load_img( 'Data/Image.jpeg',\n",
    "                         target_size=(64,64))  #based model convolutional  \n",
    "\n",
    "\n",
    "\n",
    "# convert image to array\n",
    "\n",
    "test_image=image.img_to_array(test_image)\n",
    "\n",
    "\n",
    "# we get error if we put it on classifer it need one more dimension\n",
    "#  Classifier.predict(test_image)\n",
    "\n",
    "\n",
    "# so we add one more dimension\n",
    "\n",
    "\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "Classifier.predict(test_image)\n",
    "\n",
    "# this gives us 0 or 1 to inderstand\n",
    "\n",
    "# use below\n",
    "\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.predict(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "test_image=image.load_img( 'Data/I2.jpg',\n",
    "                         target_size=(64,64))  #based model convolutional  \n",
    "\n",
    "\n",
    "\n",
    "# convert image to array\n",
    "\n",
    "test_image=image.img_to_array(test_image)\n",
    "\n",
    "\n",
    "# we get error if we put it on classifer it need one more dimension\n",
    "#  Classifier.predict(test_image)\n",
    "\n",
    "\n",
    "# so we add one more dimension\n",
    "\n",
    "\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "Classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00186344]], dtype=float32)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "test_image=image.load_img( 'Data/ii.jpg',\n",
    "                         target_size=(64,64))  #based model convolutional  \n",
    "\n",
    "\n",
    "\n",
    "# convert image to array\n",
    "\n",
    "test_image=image.img_to_array(test_image)\n",
    "\n",
    "\n",
    "# we get error if we put it on classifer it need one more dimension\n",
    "#  Classifier.predict(test_image)\n",
    "\n",
    "\n",
    "# so we add one more dimension\n",
    "\n",
    "\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "Classifier.predict(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
